{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe1e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust this if your notebook is in a subfolder (like /notebooks)\n",
    "project_root = os.path.abspath(\"..\")  # or \"../..\" if deeper\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2311aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.metrics import regression_metrics, quantile_coverage, print_metrics\n",
    "from models.linear_model import load_features_and_split, train_linear_regression\n",
    "from models.catboost_model import (train_catboost, train_catboost_quantiles, predict_interval)\n",
    "from models.xgboost_model import load_xgb_data, train_xgboost\n",
    "from models.random_forest import train_random_forest\n",
    "import matplotlib.pyplot as plt\n",
    "from config.paths import data_path\n",
    "from models.lightgbm_model import (preprocess_for_lightgbm, load_lgbm_data, train_lightgbm, train_lightgbm_quantiles, predict_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc4b20",
   "metadata": {},
   "source": [
    "General train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6e456",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.random_forest import load_rf_data, train_random_forest \n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_rf_data()\n",
    "\n",
    "# Set parameters\n",
    "rf_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": None,  # grow until all leaves are pure or min_samples rules apply\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "# Train and evaluate\n",
    "rf_model = train_random_forest(X_train, y_train, rf_params=rf_params)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print_metrics(\"Random Forest\", regression_metrics(y_test, y_pred_rf))\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Table\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "display(feat_imp_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b42e71",
   "metadata": {},
   "source": [
    "Linear regression metrics and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38546952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.paths import data_path\n",
    "from models.linear_model import load_features_and_split, train_linear_regression\n",
    "from utils.metrics import regression_metrics, summarize_coefficients\n",
    "\n",
    "def print_metrics(model_name, metrics_dict):\n",
    "    print(f\"\\nðŸ“Š Performance for {model_name}\")\n",
    "    for k, v in metrics_dict.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Choose input file\n",
    "processed_file = data_path(\"selected_features_linear.json\")\n",
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_features_and_split(processed_file)\n",
    "\n",
    "# Train model\n",
    "linreg_model = train_linear_regression(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lin = linreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "metrics = regression_metrics(y_test, y_pred_lin)\n",
    "print_metrics(\"Linear Regression\", metrics)\n",
    "\n",
    "# Show coefficients + plot\n",
    "summarize_coefficients(linreg_model, X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa6110e",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6318f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 1. Load and split data ------------------ #\n",
    "\n",
    "df = pd.read_json(data_path(\"selected_features_CB.json\"))\n",
    "X = df.drop(columns=[\"startupDelay\", \"id\"])\n",
    "y = df[\"startupDelay\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "cat_features = [\"pillar\", \"countryCoor\"]  # Categorical features as column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {\n",
    "    \"iterations\": 300,\n",
    "    \"depth\": 6,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "cb_quantile_params = cb_params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779566aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 3. Train single-value CatBoost ------------------ #\n",
    "\n",
    "cb_model = train_catboost(\n",
    "    X_train, y_train,\n",
    "    X_valid=X_test, y_valid=y_test,\n",
    "    catboost_params=cb_params,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "y_pred_cb = cb_model.predict(X_test)\n",
    "\n",
    "print_metrics(\"CatBoost (Point Prediction)\", regression_metrics(y_test, y_pred_cb))\n",
    "\n",
    "# ------------------ 4. Train quantile models ------------------ #\n",
    "\n",
    "m_low = train_catboost_quantiles(\n",
    "    X_train, y_train, alpha=0.1,\n",
    "    X_valid=X_test, y_valid=y_test,\n",
    "    catboost_quantile_params=cb_quantile_params,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "m_med = train_catboost_quantiles(\n",
    "    X_train, y_train, alpha=0.5,\n",
    "    X_valid=X_test, y_valid=y_test,\n",
    "    catboost_quantile_params=cb_quantile_params,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "m_high = train_catboost_quantiles(\n",
    "    X_train, y_train, alpha=0.9,\n",
    "    X_valid=X_test, y_valid=y_test,\n",
    "    catboost_quantile_params=cb_quantile_params,\n",
    "    cat_features=cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be024f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 5. Evaluate quantile predictions ------------------ #\n",
    "\n",
    "intervals = predict_interval(m_low, m_med, m_high, X_test)\n",
    "\n",
    "print_metrics(\"CatBoost Quantile (Median)\", regression_metrics(y_test, intervals[:, 1]))\n",
    "\n",
    "coverage_stats = quantile_coverage(y_test.values, intervals)\n",
    "print_metrics(\"Prediction Interval\", coverage_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 6. Feature Importances ------------------ #\n",
    "\n",
    "feat_imp = cb_model.get_feature_importance(prettified=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feat_imp[\"Feature Id\"], feat_imp[\"Importances\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"CatBoost Feature Importances (Point Prediction Model)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70e1db",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_xgb_data()\n",
    "\n",
    "# Set parameters\n",
    "xgb_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "xgb_model = train_xgboost(X_train, y_train, xgb_params)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print_metrics(\"XGBoost\", regression_metrics(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract importance values\n",
    "importances = xgb_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Tabular display (optional)\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "display(feat_imp_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef626cc",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_lgbm_data()\n",
    "\n",
    "# Regular training\n",
    "params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 15,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "model = train_lightgbm(X_train, y_train, lgbm_params=params)\n",
    "y_pred = model.predict(X_test)\n",
    "print_metrics(\"LightGBM Point\", regression_metrics(y_test, y_pred))\n",
    "\n",
    "# Quantile regression\n",
    "models_q = train_lightgbm_quantiles(X_train, y_train, base_params=params)\n",
    "intervals = predict_interval(models_q, X_test)\n",
    "print_metrics(\"LightGBM Quantile (Median)\", regression_metrics(y_test, intervals[:, 1]))\n",
    "print_metrics(\"Prediction Interval\", quantile_coverage(y_test.values, intervals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "importances = model.feature_importances_\n",
    "features = X_train.columns\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features[sorted_idx], importances[sorted_idx])\n",
    "plt.title(\"LightGBM Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf19b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg interval width: 220.37\n"
     ]
    }
   ],
   "source": [
    "interval_widths = intervals[:, 2] - intervals[:, 0]\n",
    "print(f\"Avg interval width: {interval_widths.mean():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
